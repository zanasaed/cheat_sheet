{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"web_crawler.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/zanasaed/NoteBook/blob/main/selenium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"EpTwQSN34Tpg"},"source":["# Scrapy\n","Udemy - Modern Web Scraping with Python using Scrapy Splash Selenium 2020-5\n","\n","this document it is not a tutorail to learn scarapy it is just a note book of importnet thighs that I think it's useful \n"]},{"cell_type":"markdown","metadata":{"id":"w68acUElpBFf"},"source":["## Install \n","\n","\n","1.   First install anaconda  and python on anaconda \n","\n","2.   create an Environment  \n","\n","3.   install scrapy on anaconda [links](https://anaconda.org/conda-forge/scrapy)\n","\n","for coding use VSC \n"]},{"cell_type":"markdown","metadata":{"id":"Xz2B7MlEqaEl"},"source":["## DOC\n","the Official [documentation](https://docs.scrapy.org/en/latest/)"]},{"cell_type":"markdown","metadata":{"id":"ozmQsU0Yr9Gf"},"source":["## Use terminal \n","go the official website for more [details](https://docs.scrapy.org/en/latest/topics/commands.html) \n","\n","open anaconda  terminal and active the Env that contains scrapy \n","\n","type `scrapy`  to see short help \n","\n","to get benchmark type `scrapy bench` \n","\n","\n","**FETCH** :  fetch a URL using the Scrapy  downloader \n","\n","to fetch a website : \n","\n","`scrapy  fetch http://google.com` \n","\n","we get back raw HTML markup of google.com \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"iCPrDjp5BB5e"},"source":["### startproject\n","[Doc](https://docs.scrapy.org/en/latest/topics/commands.html#startproject)\n","\n","\n","Syntax: scrapy startproject \\<project_name> [project_dir]\n","\n","Creates a new Scrapy project named project_name, under the project_dir directory.\n","\n","If project_dir wasnâ€™t specified, project_dir will be the same as project_name.\n","\n","Example :\n","` scrapy startproject project1 mainproject`\n","\n","\n","To handel multi project in one project look at [this](https://stackoverflow.com/questions/31662797/getting-scrapy-project-settings-when-script-is-outside-of-root-directory)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ebse0FKgBDHf"},"source":["### genspider\n","[Doc](https://docs.scrapy.org/en/latest/topics/commands.html#genspider)\n","\n","`scrapy genspider [-t template] <name> <domain>` \n","\n","**NOTE**: the URL should not end with slash \"/\" in domain variable  and not start with \"https://\" or \"http://\" \n"]},{"cell_type":"markdown","metadata":{"id":"3WEIA3qV--9k"},"source":["## Spider \n","Doc \n","\n","**some crazy note**\n","\n","we can't add \"http\" or \"https\" to the start of allowed_domains in spider\n"," \n"," <font color='red'> Wrong use </font> : \n","\n","`allowed_domains = ['https://www.google.com']`\n","\n","`allowed_domains = ['http://www.google.com']`\n","\n","scrapy in default use http methode so for thoese website that use https change the \"start_urls in spider :\n","`start_urls = ['https://google.com']`\n","\n"]},{"cell_type":"code","metadata":{"id":"mU8CIjYP4Vr3"},"source":[""],"execution_count":null,"outputs":[]}]}